# My Scrap Project

A web scraping project utilizing Scrapy to extract data from online listings. this is using url hardcoded in the spider

## ğŸ› ï¸ Prerequisites

Before running the project, ensure you have the following installed:

- [Docker](https://www.docker.com/get-started)
- [Git](https://git-scm.com/)

## ğŸ“¦ Project Structure

The project directory contains:

- `Dockerfile`: Docker configuration for the project.
- `scrapy.cfg`: Scrapy project configuration file.
- `requirements.txt`: Python dependencies.
- `my_scrap_project/`: Scrapy project directory containing spiders and settings.

## ğŸ³ Running with Docker

### 1. Clone the Repository

git clone https://github.com/kavindaktk2025/my-scrap-project.git
cd my-scrap-project

### 2. Build the Docker Image

docker build -t my-scrap-project .

### 2. My Scrap Project

A web scraping project utilizing Scrapy to extract data from online listings.

## ğŸ› ï¸ Prerequisites

Before running the project, ensure you have the following installed:

- [Docker](https://www.docker.com/get-started)
- [Docker Compose](https://docs.docker.com/compose/install/)
- [Git](https://git-scm.com/)

## ğŸ“¦ Project Structure

The project directory contains:

- `Dockerfile`: Docker configuration for the project.
- `docker-compose.yml`: Docker Compose configuration for multi-container setup.
- `scrapy.cfg`: Scrapy project configuration file.
- `requirements.txt`: Python dependencies.
- `my_scrap_project/`: Scrapy project directory containing spiders and settings.

## ğŸ³ Running with Docker

### 1. Clone the Repository

